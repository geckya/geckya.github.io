<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>on Amanda Alvarez</title><link>https://gecky.me/</link><description>Recent content in on Amanda Alvarez</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 11 Dec 2022 00:00:01 +0000</lastBuildDate><atom:link href="https://gecky.me/index.xml" rel="self" type="application/rss+xml"/><item><title>Dimensions of Data Quality</title><link>https://gecky.me/posts/data-quality-dimensions/</link><pubDate>Sun, 11 Dec 2022 00:00:01 +0000</pubDate><guid>https://gecky.me/posts/data-quality-dimensions/</guid><description>Everyone wants &amp;ldquo;good&amp;rdquo; data. Almost as universal is the sense that the data you&amp;rsquo;re working with is&amp;hellip;not good. Being able to objectively measure data quality is important for ensuring downstream modeling and decision making is built on reliable data, but it can be hard to measure and report on data quality without a framework for identifying what features of the data are good/bad.
Metadata features with expectations that can be defined (and measured against!</description></item><item><title>Minimizing the Cost Function in Data Projects (or, Keep it Simple, Stupid)</title><link>https://gecky.me/posts/lightning-talk/</link><pubDate>Mon, 05 Dec 2022 00:00:01 +0000</pubDate><guid>https://gecky.me/posts/lightning-talk/</guid><description>I&amp;rsquo;ve been working in data and computational science in various capacities in geophysics, finance, civic tech, social good, business analytics, and numerous hobbies for nearly 20 years. In that time, one universal truth I&amp;rsquo;ve found is that data work can get complicated fast. Even the so-called easy things like counting, time, measurements, and naming things aren&amp;rsquo;t always easy, but sometimes we make them harder than they need to be. It&amp;rsquo;s a constant battle to remember that a complicated solution might be fun to build, but it&amp;rsquo;s better to start simple and only add complexity where it&amp;rsquo;s merited.</description></item><item><title>NormConf is Coming!</title><link>https://gecky.me/posts/normconf-is-coming/</link><pubDate>Sat, 03 Dec 2022 21:10:51 -0700</pubDate><guid>https://gecky.me/posts/normconf-is-coming/</guid><description>NormConf, the coolest conference to ever be tweeted into existence, is coming! The main event, with live talks, happens across 15+ glorious hours on 2022-12-15, but the Lightning Talks (prerecorded 5 minute presentations) will be released ten days earlier - that&amp;rsquo;s the day after tomorrow.
I&amp;rsquo;m giving a meme-loaded Lightning Talk titled Minimizing the Cost Function in Data Projects (or, Keep it Simple, Stupid). Five minutes isn&amp;rsquo;t much time, and I&amp;rsquo;ve definitely got more thoughts, so I&amp;rsquo;m looking forward to continuing the discussion afterward - here, on the NormConf Slack, and anywhere else I find someone willing to listen to me rant about data product design and maintenance.</description></item><item><title>About</title><link>https://gecky.me/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gecky.me/about/</guid><description>Hi, I&amp;rsquo;m Amanda. I&amp;rsquo;ve worn a lot of hats working with data in geophysics, finance, civic tech, social good projects, business analytics, and numerous hobbies for a long time. I have strong feelings about the design and management of data products.
Outside my data work, I enjoy various fiber arts, rock climbing, baking, tacos, and helping my kids explore new hobbies/passions of their own.</description></item></channel></rss>