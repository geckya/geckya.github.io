<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>data ops on Amanda Alvarez</title><link>https://gecky.me/tags/data-ops/</link><description>Recent content in data ops on Amanda Alvarez</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 12 Dec 2022 00:00:01 +0000</lastBuildDate><atom:link href="https://gecky.me/tags/data-ops/index.xml" rel="self" type="application/rss+xml"/><item><title>SMART Data Ops</title><link>https://gecky.me/posts/smart-quality-checks/</link><pubDate>Mon, 12 Dec 2022 00:00:01 +0000</pubDate><guid>https://gecky.me/posts/smart-quality-checks/</guid><description>Data quality checks are a critical tool in the data pro&amp;rsquo;s toolbox to ensure SLAs are maintained, but poorly designed checks can lead to a life of on-call misery, a constant flow of &amp;ldquo;why is this data wrong?&amp;rdquo; inquiries, or (worst of all) unecessarily Bad Data. But what makes a good data quality check?
Specific - Willy Wonka&amp;rsquo;s egg checker returned two possible values - &amp;ldquo;good&amp;rdquo; and &amp;ldquo;bad&amp;rdquo; - but data quality checks don&amp;rsquo;t (and shouldn&amp;rsquo;t!</description></item><item><title>Dimensions of Data Quality</title><link>https://gecky.me/posts/data-quality-dimensions/</link><pubDate>Sun, 11 Dec 2022 00:00:01 +0000</pubDate><guid>https://gecky.me/posts/data-quality-dimensions/</guid><description>Everyone wants &amp;ldquo;good&amp;rdquo; data. Almost as universal is the sense that the data you&amp;rsquo;re working with is&amp;hellip;not good. Being able to objectively measure data quality is important for ensuring downstream modeling and decision making is built on reliable data, but it can be hard to measure and report on data quality without a framework for identifying what features of the data are good/bad.
Data features with expectations that can be defined (and measured against!</description></item></channel></rss>